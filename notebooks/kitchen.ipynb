{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pastiche import tables\n",
    "from pastiche.database import SessionLocal\n",
    "from datetime import date\n",
    "from pastiche import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SessionLocal() as db:\n",
    "    solutions = db.query(tables.JumbleGame).order_by(tables.JumbleGame.value_date).limit(100).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def generate_dall_e_prompt(client: OpenAI, clue_sentence: str, solution: str, model: str = 'gtp-4'):\n",
    "    prompt = f\"\"\"\n",
    "    Generate a promt for text-to-image generation following the guidelines below:\n",
    "    \\n\n",
    "    1. Identify Key Elements: Focus on the main elements of both the clue-sentence and the solution. This could be objects, actions, or themes.\n",
    "    2. Visual Representation: Translate these elements into visual cues that can be illustrated. For example, if the solution is a play on words, I consider how to represent that pun visually.\n",
    "    3. Avoid Direct Depiction of Solution: Make sure the image suggests the solution without explicitly showing it. This often involves using metaphors or related imagery.\n",
    "    4. Context and Setting: Provide a setting or context that aligns with the clue-sentence, enhancing the overall theme.\n",
    "    5. Detail and Description: The prompt is detailed and descriptive to guide the AI in generating an image that closely matches the intended idea.\n",
    "    6. To the point: only return the prompt and nothing else\n",
    "    \\n\n",
    "    Clue-sentence: '{clue_sentence}'\\nSolution: '{solution}'\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def generate_image(client: OpenAI, prompt: str, model: str = 'dall-e-3'):\n",
    "    response = client.images.generate(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "    \n",
    "    return response.data[0].url\n",
    "\n",
    "\n",
    "\n",
    "def download_image(url, filename):\n",
    "    # Open the url image, set stream to True, this will return the stream content.\n",
    "    r = requests.get(url, stream = True)\n",
    "\n",
    "    # Check if the image was retrieved successfully\n",
    "    if r.status_code == 200:\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        r.raw.decode_content = True\n",
    "        \n",
    "        # Open a local file with wb ( write binary ) permission and write the contents of the response to it.\n",
    "        with open(filename,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "        \n",
    "        print('Image sucessfully Downloaded: ',filename)\n",
    "    else:\n",
    "        print('Image Couldn\\'t be retreived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "image_prompt = generate_dall_e_prompt(client, s.clue_sentence, s.solution_unjumbled)\n",
    "\n",
    "image_url = generate_image(client, image_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded:  /Users/badrbenmbarek/Documents/work/perso/pastiche/data/images/tst.jpg\n"
     ]
    }
   ],
   "source": [
    "filename = config.DATA_DIR / \"images/tst.jpg\"\n",
    "download_image(image_url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "\n",
    "    blob.upload_from_filename(source_file_name, if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../data/images/v1/1.jpg uploaded to v1/1.jpg.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(\n",
    "    bucket_name=\"pastiche-images\",\n",
    "    source_file_name=\"../data/images/v1/1.jpg\",\n",
    "    destination_blob_name=\"v1/1.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pastiche.game import JumbleGame, JumbleGameCollection\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/jumble_answers_data.json'\n",
    "\n",
    "data = JumbleGameCollection.from_jumble_answers(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = data.games[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.solution, game.solution_unjumbled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_solution(solution: str, letters: str, sub: str = \"*\"):\n",
    "    \"\"\"\n",
    "    Sanitises a solution by replacing all letters present in solution by _ without touching the words special characters or worlds between ()\n",
    "    example:\n",
    "    sanitize_solution('DAY IN (AND) DAY OUT', 'DAYINDAYOUT')\n",
    "    >>> '*** ** (AND) *** ***'\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    in_parenthesis = False\n",
    "    for character in solution:\n",
    "        # Check if character is '(', and then we start skipping\n",
    "        if character == '(':\n",
    "            in_parenthesis = True\n",
    "        # Check if character is ')', and then we stop skipping\n",
    "        elif character == ')':\n",
    "            in_parenthesis = False\n",
    "        # If character is not in parenthesis & found in letters, replace it with sub\n",
    "        if not in_parenthesis and character.upper() in letters.upper() and character.isalpha():\n",
    "            output.append(sub)\n",
    "        else: # Append the character as it is.\n",
    "            output.append(character)\n",
    "    return ''.join(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in solutions:\n",
    "    sanitized = sanitize_solution(s.solution_unjumbled, s.solution)\n",
    "    print(s.solution_unjumbled, \"|\", sanitized)\n",
    "    assert len(sanitized) == len(s.solution_unjumbled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dates = [date(2022, 1, 1), date(2022, 1, 2), date(2022, 1, 5), date(2022, 1, 6), date(2022, 1, 10)]\n",
    "\n",
    "date_range = [value_dates[0] + timedelta(days=x)\n",
    "              for x in range((value_dates[-1]-value_dates[0]).days + 1)]\n",
    "\n",
    "dates_to_check = [(t, t in value_dates) for t in date_range]\n",
    "\n",
    "consecutive_dates = []\n",
    "for k, g in groupby(enumerate(dates_to_check), lambda x: x[1]):\n",
    "    if k[1]:\n",
    "        consecutive_dates.append(list(map(lambda x: k[0], list(g))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dates = [{'valueDate': 'Thursday, November 09 2023', 'elapsedTime': 4163}, {'valueDate': 'Thursday, November 09 2023', 'elapsedTime': 6661}, {'valueDate': 'Thursday, November 09 2023', 'elapsedTime': 4921}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pastiche import config\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(value_dates)\n",
    "df['valueDate'] = df['valueDate'].apply(\n",
    "    lambda x: datetime.strptime(x, config.DISPLAY_DATE_FORMAT)\n",
    ")\n",
    "fastest_time = df['elapsedTime'].min()\n",
    "\n",
    "df.set_index('valueDate', inplace=True)\n",
    "df = df.resample(\"D\").first()\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "played_dates = ~df['elapsedTime'].isnull()\n",
    "\n",
    "consecutive_dates = []\n",
    "for k, g in groupby(enumerate(played_dates), lambda x: x[1]):\n",
    "    if k:\n",
    "        consecutive_dates.append(list(map(lambda x: x[0], list(g))))\n",
    "        \n",
    "max_streak = max([len(t) for t in consecutive_dates])\n",
    "current_streak = [len(t) for t in consecutive_dates][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastest_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "millify(fastest_time, prefixes=\"min\", precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastest_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "        \"“PURR” HIS REQUEST\": \"“PURR” (HIS) REQUEST\",\n",
    "        \"ASSIGNED THE JOB\": \"ASSIGNED (THE) JOB\",\n",
    "        \"FOR THE BIRDS\": \"FOR (THE) BIRDS\",\n",
    "        \"GO HAND IN HAND\": \"GO HAND (IN) HAND\",\n",
    "        \"ALL IN A DAY’S WORK\": \"ALL IN (A) DAY’S WORK\",\n",
    "        \"LOST HIS SHIRT\": \"LOST (HIS) SHIRT\",\n",
    "        \"HOT UNDER THE COLLAR\": \"HOT UNDER (THE) COLLAR\",\n",
    "        \"BORE THE BRUNT OF IT\": \"BORE (THE) BRUNT OF IT\",\n",
    "        \"BREAK IT TO HER\": \"BREAK (IT) TO HER\",\n",
    "        \"FILLED THE BILL\": \"FILLED (THE) BILL\",\n",
    "        \"ROAD TO RECOVERY\": \"ROAD (TO) RECOVERY\",\n",
    "        \"COURT FOR THE COURT\": \"COURT FOR (THE) COURT\",\n",
    "        \"MADE A NAME FOR HIMSELF\": \"MADE A NAME (FOR) HIMSELF\",\n",
    "        \"“WRITE” FOR THE JOB\": \"“WRITE” FOR (THE) JOB\",\n",
    "        \"LEFT THE PREMISES\": \"LEFT (THE) PREMISES\",\n",
    "        \"DOWN TO A TRICKLE\": \"DOWN (TO) A TRICKLE\",\n",
    "        \"END OF THE “RODE”\": \"END OF (THE) “RODE”\",\n",
    "        \"RAISING HER CHILDREN\": \"RAISING (HER) CHILDREN\",\n",
    "        \"BANNED THE BAND\": \"BANNED (THE) BAND\",\n",
    "        \"HAD THE UPPER HAND\": \"HAD (THE) UPPER HAND\",\n",
    "        \"BEAR TO THE RIGHT\": \"BEAR TO (THE) RIGHT\",\n",
    "        \"SEEING WAS BELIEVING\": \"SEEING (WAS) BELIEVING\",\n",
    "        \"THROUGH THE ROOF\": \"THROUGH (THE) ROOF\",\n",
    "        \"HEART OF THE CITY\": \"HEART OF (THE) CITY\",\n",
    "        \"KEEP AN OPEN MIND\": \"KEEP (AN) OPEN MIND\",\n",
    "        \"HAS A “FLARE” FOR IT\": \"HAS (A) “FLARE” FOR IT\",\n",
    "        \"LOST HIS BALANCE\": \"LOST (HIS) BALANCE\",\n",
    "        \"DOWN THE HATCH\": \"DOWN (THE) HATCH\",\n",
    "        \"REFUSE THE REFUSE\": \"REFUSE (THE) REFUSE\",\n",
    "        \"TO SAY THE “LEASED”\": \"TO SAY (THE) “LEASED”\",\n",
    "        \"“WAY” THEIR OPTIONS\": \"“WAY” (THEIR) OPTIONS\"\n",
    "     }\n",
    "\n",
    "# df['solution_unjumbled'] = df['solution_unjumbled'].replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pydantic import Field\n",
    "from openai_function_call import OpenAISchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class JumbleClue(OpenAISchema):\n",
    "#     \"\"\"Class representing a sentence used as a clue for a Jumble game\"\"\"\n",
    "#     clue_sentence: str = Field(..., description=\"Sentence with gaps to be filled.\")\n",
    "#     solution: str = Field(..., description=\"The words to use to fill the gaps in the clue-sentence. The solution can be made of multiple words and these words are not separated by a space.\")\n",
    "#     full_sentence: str = Field(..., description=\"The full sentence with all words.\")\n",
    "    \n",
    "# class JumbleCluesCollection(OpenAISchema):\n",
    "#     \"\"\"List of jumble clues\"\"\"\n",
    "#     clues: list[JumbleClue]\n",
    "    \n",
    "# prompt1 = \"\"\"\n",
    "# Consider the data below: '\\n{data}'. \n",
    "#                 For each entry in the list, follow the following steps:\n",
    "#                 1. identify where are the gaps in the `clue_sentence`.\n",
    "#                 2. reconstruct the correct words using the `solution` by adding missing spaces\n",
    "#                 3. use the reconstructed solution to create a `full_sentence` by filling the gaps in the `clue_sentence`\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumbleClue(OpenAISchema):\n",
    "    \"\"\"Class representing a sentence used as a clue for a Jumble game\"\"\"\n",
    "    word: str = Field(..., description=\"A list of letters defining one or multiple words without any space\")\n",
    "    word_with_spaces: str | None = Field(..., description=\"list of words recreated from `word` with the missing spaces added\")\n",
    "    \n",
    "class JumbleCluesCollection(OpenAISchema):\n",
    "    \"\"\"List of jumble clues\"\"\"\n",
    "    clues: list[JumbleClue]\n",
    "   \n",
    "prompt2 = \"\"\"\n",
    "Consider the data below: '\\n{data}'. For each word, reconstruct the correct words by adding missing spaces.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jumble_clues(data: str) -> JumbleCluesCollection:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0.1,\n",
    "        functions=[JumbleCluesCollection.openai_schema],\n",
    "        function_call={\"name\": JumbleCluesCollection.openai_schema[\"name\"]},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Consider the data below: '\\n{data}'. For each word, reconstruct the correct words by adding missing spaces. If you can't find a match please return None.\"\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    return JumbleCluesCollection.from_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_jumble_clues(\n",
    "    data=solutions[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
